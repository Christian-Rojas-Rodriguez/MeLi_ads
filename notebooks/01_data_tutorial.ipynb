{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Tutorial\n",
                "\n",
                "This notebook demonstrates how to use the `src/meli_ads/data` module to load and transform the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Ensure src is in python path\n",
                "project_root = Path(os.getcwd()).parents[0]\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.append(str(project_root))\n",
                "\n",
                "from src.meli_ads.data import MeliChallengeDataset\n",
                "from src.meli_ads.data.transforms import HistoryFeatureExtractor"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize Dataset\n",
                "\n",
                "We initialize the dataset pointing to the raw data directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize dataset with the transformer\n",
                "dataset = MeliChallengeDataset(\n",
                "    data_dir='../data/raw',\n",
                "    transform=HistoryFeatureExtractor()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data\n",
                "\n",
                "Load the training data (first 1000 rows for speed)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_train = dataset.load_train(nrows=1000)\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Apply Transforms\n",
                "\n",
                "The `load_train` returns the raw pandas DataFrame. \n",
                "To get a **transformed** example (with features extracted), we use `get_example(index)`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the 0-th example, transformed\n",
                "example = dataset.get_example(0, dataset='train')\n",
                "\n",
                "print(\"Transformed Keys:\", example.keys())\n",
                "print(\"Num Events:\", example['num_events'])\n",
                "print(\"Item Bought:\", example['item_bought'])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}